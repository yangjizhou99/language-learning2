"use client";
import React, { useEffect, useRef, useState, useCallback } from "react";

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

interface SpeechRecognition extends EventTarget {
  lang: string;
  interimResults: boolean;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: (event: SpeechRecognitionEvent) => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  onend: () => void;
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}
import { supabase } from "@/lib/supabase";
// ä»…ä½¿ç”¨æµè§ˆå™¨åŸç”Ÿè¯†åˆ«ï¼›ç§»é™¤ç¬¬ä¸‰æ–¹ ASR ä¾èµ–
import { scorePronunciation, splitSentences } from "@/lib/asr/align";

type ShadowingData = { text: string; lang: "ja"|"en"|"zh"; topic: string; approx_duration_sec?: number };

const MODELS = [
  { id: "deepseek-chat", label: "deepseek-chatï¼ˆæ¨èï¼‰" },
  { id: "deepseek-reasoner", label: "deepseek-reasoner" },
];

export default function ShadowingPage() {
  const [lang, setLang] = useState<"ja"|"en"|"zh">("ja");
  const [topic, setTopic] = useState(lang === "ja" ? "æ—¥ç¨‹ã®èª¿æ•´" : lang === "zh" ? "è‡ªæˆ‘ä»‹ç»" : "Travel plan");
  const [model, setModel] = useState("deepseek-chat");
  const [loading, setLoading] = useState(false);
  const [data, setData] = useState<ShadowingData|null>(null);
  const [err, setErr] = useState("");

  // TTS
  const [voices, setVoices] = useState<{name:string; type:string; ssmlGender:string; naturalSampleRateHertz:number}[]>([]);
  const [voiceName, setVoiceName] = useState<string>("");
  const [rate, setRate] = useState<number>(1.0);
  const [pitch, setPitch] = useState<number>(0);
  const [ttsBlob, setTtsBlob] = useState<Blob|null>(null);
  const [ttsUrl, setTtsUrl] = useState<string>("");

  // MediaRecorder
  const [recState, setRecState] = useState<"idle"|"recording"|"stopped">("idle");
  const mediaStreamRef = useRef<MediaStream|null>(null);
  const recorderRef = useRef<MediaRecorder|null>(null);
  const chunksRef = useRef<BlobPart[]>([]);
  const [localUrl, setLocalUrl] = useState<string>("");
  const [recordedBlob, setRecordedBlob] = useState<Blob|null>(null);

  // ASR Stateï¼ˆä»…ä½¿ç”¨æµè§ˆå™¨åŸç”Ÿè¯†åˆ«ï¼šChrome Web Speech / Safari webkitSpeechRecognitionï¼‰
  const [asrText, setAsrText] = useState("");
  const [asrLoading, setAsrLoading] = useState(false);
  const [asrScore, setAsrScore] = useState<{accuracy:number; coverage:number; speed_wpm?:number} | null>(null);
  const [asrDetail, setAsrDetail] = useState<{ref:string[]; hyp:string[]}>({ref:[], hyp:[]});
  // AI å»ºè®®
  const [adviceLoading, setAdviceLoading] = useState(false);
  const [adviceText, setAdviceText] = useState("");
  const [adviceErr, setAdviceErr] = useState("");

  // è¯†åˆ«æ§åˆ¶
  const recognitionRef = useRef<{ stop: () => void } | null>(null);
  const recognitionPromiseRef = useRef<Promise<string> | null>(null);

  // å½“è¯­è¨€å˜åŒ–æˆ–ç‚¹å‡»â€œåˆ·æ–°å£°éŸ³â€æ—¶è·å–å£°éŸ³åˆ—è¡¨
  const fetchVoices = useCallback(async (kind: "Neural2" | "WaveNet" | "Standard" | "all" = "Neural2") => {
    try {
      const r = await fetch(`/api/tts/voices?lang=${lang}&kind=${kind}`);
      const j = await r.json();
      if (Array.isArray(j)) {
        setVoices(j);
        // è‡ªåŠ¨é€‰ç¬¬ä¸€ä¸ª
        if (j.length && !voiceName) setVoiceName(j[0].name);
      } else {
        setErr(j?.error || "æ— æ³•è·å–å£°éŸ³åˆ—è¡¨");
      }
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "æ— æ³•è·å–å£°éŸ³åˆ—è¡¨");
    }
  }, [lang, voiceName]);

  // é¡µé¢æŒ‚è½½æˆ– lang æ”¹å˜æ—¶åˆ·æ–°
  useEffect(() => {
    setVoiceName("");
    // ä¸­æ–‡é»˜è®¤å–å…¨éƒ¨ï¼Œé¿å…æ²¡æœ‰ä¸­æ–‡é€‰é¡¹
    fetchVoices(lang === "zh" ? "all" : "Neural2");
  }, [lang, fetchVoices]);

  // Google æœåŠ¡ç«¯åˆæˆï¼ˆå¤±è´¥å›é€€ Web Speechï¼‰
  const synthGoogle = async () => {
    if (!data?.text) return;
    setErr("");
    try {
      const res = await fetch("/api/tts", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          text: data.text,
          lang,
          voiceName: voiceName || undefined,
          speakingRate: rate,
          pitch
        })
      });
      if (!res.ok) {
        // å›é€€
        speak();
        const t = await res.text();
        setErr(`Google TTS å¤±è´¥ï¼Œå·²å›é€€æœ¬åœ°åˆæˆï¼š${t.slice(0,200)}`);
        return;
      }
      const ab = await res.arrayBuffer();
      const blob = new Blob([ab], { type: "audio/mpeg" });
      setTtsBlob(blob);
      const url = URL.createObjectURL(blob);
      setTtsUrl(url);
    } catch (e: unknown) {
      speak();
      setErr(e instanceof Error ? e.message : "TTS ç½‘ç»œé”™è¯¯ï¼Œå·²å›é€€ Web Speech");
    }
  };

  // Web Speech æœ¬åœ°åˆæˆ
  const speak = () => {
    if (!data?.text) return;
    const synth = window.speechSynthesis;
    if (!synth) { alert("æ­¤æµè§ˆå™¨ä¸æ”¯æŒ Web Speech TTS"); return; }
    const u = new SpeechSynthesisUtterance(data.text);
    // å°è¯•é€‰æ‹©å¯¹åº”è¯­è¨€çš„ voice
    const voices = synth.getVoices();
    const targetLang = lang === "ja" ? "ja" : lang === "zh" ? "zh" : "en";
    const v = voices.find(v => v.lang?.toLowerCase().startsWith(targetLang));
    if (v) u.voice = v;
    u.rate = 1.0;
    u.pitch = 1.0;
    synth.cancel();
    synth.speak(u);
  };

  // ä¿å­˜åˆ° tts æ¡¶
  const saveTts = async () => {
    try {
      if (!ttsBlob) { setErr("æ²¡æœ‰å¯ä¿å­˜çš„ TTS éŸ³é¢‘"); return; }
      const { data: u } = await supabase.auth.getUser();
      const uid = u?.user?.id;
      if (!uid) { setErr("æœªç™»å½•"); return; }
      const ts = Date.now();
      const path = `${uid}/tts-${ts}.mp3`;
      const { error: upErr } = await supabase.storage.from("tts").upload(path, ttsBlob, {
        cacheControl: "3600", upsert: false, contentType: "audio/mpeg",
      });
      if (upErr) { setErr(upErr.message); return; }
      const { data: signed, error: sErr } = await supabase.storage.from("tts").createSignedUrl(path, 60*60*24*7);
      if (sErr) { setErr(sErr.message); return; }
      setTtsUrl(signed!.signedUrl);
      alert("TTS å·²ä¿å­˜åˆ°æˆ‘çš„åº“ï¼ˆé“¾æ¥ 7 å¤©æœ‰æ•ˆï¼‰");
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "ä¿å­˜å¤±è´¥");
    }
  };

  // å½•éŸ³åŠŸèƒ½ä¿æŒä¸å˜
  const startRec = async () => {
    setErr("");
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      const rec = new MediaRecorder(stream, { mimeType: "audio/webm" });
      recorderRef.current = rec;
      chunksRef.current = [];
      // å¼€å§‹æ–°å½•éŸ³å‰æ¸…ç†æ—§çš„æœ¬åœ°éŸ³é¢‘ä¸è¯„æµ‹è¾“å…¥
      setLocalUrl("");
      setRecordedBlob(null);
      rec.ondataavailable = (e: BlobEvent) => { if (e.data?.size) chunksRef.current.push(e.data); };
      rec.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        const url = URL.createObjectURL(blob);
        setLocalUrl(url);
        // å…³é”®ï¼šä¿å­˜å½•éŸ³ Blob ä¾›è¯„æµ‹ä½¿ç”¨
        setRecordedBlob(blob);
      };
      rec.start();
      setRecState("recording");
    } catch (e) {
      setErr(e instanceof Error ? e.message : "æ— æ³•è®¿é—®éº¦å…‹é£");
    }
  };

  const stopRec = () => {
    recorderRef.current?.stop();
    mediaStreamRef.current?.getTracks().forEach(t => t.stop());
    setRecState("stopped");
  };

  const upload = async () => {
    try {
      const { data: u } = await supabase.auth.getUser();
      const uid = u?.user?.id;
      if (!uid) { setErr("æœªç™»å½•"); return; }
      if (chunksRef.current.length === 0) { setErr("æ²¡æœ‰å½•éŸ³æ•°æ®"); return; }

      const blob = new Blob(chunksRef.current, { type: "audio/webm" });
      const ts = Date.now();
      const path = `${uid}/${ts}.webm`;

      const { error: upErr } = await supabase.storage.from("recordings").upload(path, blob, {
        cacheControl: "3600",
        upsert: false,
        contentType: "audio/webm",
      });
      if (upErr) { setErr(upErr.message); return; }

      // ç”Ÿæˆä¸€ä¸ªçŸ­æœŸç­¾å URLï¼ˆ7 å¤©ï¼‰
      const { data: signed, error: sErr } = await supabase.storage
        .from("recordings")
        .createSignedUrl(path, 60 * 60 * 24 * 7);
      if (sErr) { setErr(sErr.message); return; }

      // å†™å…¥ sessions
      if (data) {
        await supabase.from("sessions").insert({
          user_id: uid,
          task_type: "shadowing",
          lang: data.lang,
          topic: data.topic,
          input: { text: data.text },
          output: { audio_path: path, audio_url: signed?.signedUrl },
          ai_feedback: null,
          score: null
        });
      }

      alert("ä¸Šä¼ æˆåŠŸ");
    } catch (e) {
      setErr(e instanceof Error ? e.message : "ä¸Šä¼ å¤±è´¥");
    }
  };

  const gen = async () => {
    setErr(""); setLoading(true); setData(null); setLocalUrl(""); setRecState("idle");
    try {
      const r = await fetch("/api/generate/shadowing", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ lang, topic, model })
      });
      const j = await r.json();
      if (!r.ok) setErr(j?.error || "ç”Ÿæˆå¤±è´¥"); else setData(j);
    } catch (e) {
      setErr(e instanceof Error ? e.message : "ç½‘ç»œé”™è¯¯");
    } finally {
      setLoading(false);
    }
  };

  // åˆå¹¶ï¼šå¼€å§‹å½•éŸ³ + æµè§ˆå™¨è¯†åˆ«
  const startLiveAssess = async () => {
    setErr(""); setAsrLoading(true); setAsrText(""); setAsrScore(null); setAsrDetail({ref:[], hyp:[]});
    try {
      // 1) å¯åŠ¨éº¦å…‹é£å½•éŸ³
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      const rec = new MediaRecorder(stream, { mimeType: "audio/webm" });
      recorderRef.current = rec;
      chunksRef.current = [];
      setLocalUrl("");
      setRecordedBlob(null);
      rec.ondataavailable = (e: BlobEvent) => { if (e.data?.size) chunksRef.current.push(e.data); };
      rec.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        const url = URL.createObjectURL(blob);
        setLocalUrl(url);
        setRecordedBlob(blob);
      };
      rec.start();
      setRecState("recording");

      // 2) å¯åŠ¨æµè§ˆå™¨è¯­éŸ³è¯†åˆ«ï¼ˆChrome/Safariï¼‰
      recognitionPromiseRef.current = transcribeWithBrowserRecognition(lang, (ctrl: { stop: () => void }) => {
        recognitionRef.current = ctrl;
      });
    } catch (e) {
      setAsrLoading(false);
      setErr(e instanceof Error ? e.message : "æ— æ³•è®¿é—®éº¦å…‹é£æˆ–å¯åŠ¨è¯†åˆ«");
    }
  };

  const stopLiveAssess = async () => {
    try {
      // åœæ­¢å½•éŸ³ä¸éº¦å…‹é£
      recorderRef.current?.stop();
      mediaStreamRef.current?.getTracks().forEach(t => t.stop());
      setRecState("stopped");
      // åœæ­¢è¯†åˆ«
      recognitionRef.current?.stop();

      // ç­‰å¾…è¯†åˆ«ç»“æœ
      const rawHyp = (await recognitionPromiseRef.current) || "";
      // å…ˆæŒ‰å‚è€ƒæ–‡æœ¬é£æ ¼è¡¥å…¨æ ‡ç‚¹
      const refText = data?.text || "";
      const punctuated = await punctuateText(refText, rawHyp, lang, model);
      setAsrText(punctuated);

      // è¯„åˆ†ä¸é€å¥å¯¹é½
      const sc = scorePronunciation(refText, punctuated, lang);
      setAsrScore(sc);
      setAsrDetail({ ref: splitSentences(refText, lang), hyp: splitSentences(punctuated, lang) });

      // åŸºäºè¯„æµ‹ç»“æœè°ƒç”¨ DeepSeekï¼Œç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
      await generateTargetedAdvice(refText, punctuated, sc);

      // å†™å…¥ sessions
      const { data: u } = await supabase.auth.getUser();
      if (u?.user?.id) {
        await supabase.from("sessions").insert({
          user_id: u.user.id,
          task_type: "shadowing",
          lang,
          topic: data?.topic,
          input: { text: refText },
          output: { asr_text: punctuated, asr_text_raw: rawHyp, tts_url: ttsUrl || null },
          ai_feedback: { method: "web-speech" },
          score: sc.accuracy
        });
      }
    } catch (e) {
      setErr(e instanceof Error ? e.message : "è¯„æµ‹å¤±è´¥");
    } finally {
      setAsrLoading(false);
      recognitionRef.current = null;
      recognitionPromiseRef.current = null;
    }
  };

  async function generateTargetedAdvice(refText: string, hyp: string, sc: {accuracy:number; coverage:number; speed_wpm?:number}) {
    try {
      setAdviceErr(""); setAdviceText(""); setAdviceLoading(true);
      const res = await fetch("/api/advice", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ lang, ref: refText, hyp, metrics: sc, model })
      });
      const txt = await res.text();
      if (!res.ok) { setAdviceErr(txt || "ç”Ÿæˆå»ºè®®å¤±è´¥"); return; }
      setAdviceText(txt);
    } catch (e) {
      setAdviceErr(e instanceof Error ? e.message : "ç”Ÿæˆå»ºè®®å¤±è´¥");
    } finally {
      setAdviceLoading(false);
    }
  }

  async function punctuateText(refText: string, hyp: string, lang: "ja"|"en"|"zh", modelId: string): Promise<string> {
    try {
      const res = await fetch("/api/eval/punctuate", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ lang, ref: refText, hyp, model: modelId })
      });
      const txt = await res.text();
      return res.ok ? (txt || hyp) : hyp;
    } catch {
      return hyp;
    }
  }

  // é€å¥å¯¹æ¯”é«˜äº®ï¼šLCS æ ‡æ³¨åŒ¹é…/ä¸åŒ¹é…
  function lcsFlags(a: string, b: string): { aFlags: boolean[]; bFlags: boolean[] } {
    const arrA = Array.from(a);
    const arrB = Array.from(b);
    const n = arrA.length, m = arrB.length;
    const dp: number[][] = Array.from({ length: n + 1 }, () => new Array<number>(m + 1).fill(0));
    for (let i = 1; i <= n; i++) {
      for (let j = 1; j <= m; j++) {
        if (arrA[i - 1] === arrB[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1; else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);
      }
    }
    const aFlags = new Array<boolean>(n).fill(false);
    const bFlags = new Array<boolean>(m).fill(false);
    let i = n, j = m;
    while (i > 0 && j > 0) {
      if (arrA[i - 1] === arrB[j - 1]) { aFlags[i - 1] = true; bFlags[j - 1] = true; i--; j--; }
      else if (dp[i - 1][j] >= dp[i][j - 1]) i--; else j--;
    }
    return { aFlags, bFlags };
  }

  function renderDiffLine(text: string, flags: boolean[]) {
    const chars = Array.from(text);
    return (
      <span>
        {chars.map((ch, idx) => (
          <span key={idx} className={flags[idx] ? "text-emerald-700" : "text-red-600"}>{ch}</span>
        ))}
      </span>
    );
  }

  // æ—§ evaluate é€»è¾‘å·²å¼ƒç”¨ï¼ˆåˆå¹¶ä¸º start/stop æµç¨‹ï¼‰

  // Web Speech å›é€€ï¼ˆæç®€ç¤ºä¾‹ï¼‰
  async function transcribeWithWebSpeech(lang: string): Promise<string> {
    interface WebSpeechRecognitionEvent extends Event {
      results: SpeechRecognitionResultList;
    }

    interface WebSpeechRecognitionErrorEvent extends Event {
      error: string;
    }

    interface WebSpeechRecognition extends EventTarget {
      lang: string;
      interimResults: boolean;
      maxAlternatives: number;
      continuous: boolean;
      start(): void;
      onresult: (event: WebSpeechRecognitionEvent) => void;
      onerror: (event: WebSpeechRecognitionErrorEvent) => void;
      onend: () => void;
    }

    const SR = ((window as unknown) as {
      SpeechRecognition?: new() => WebSpeechRecognition;
      webkitSpeechRecognition?: new() => WebSpeechRecognition;
    }).SpeechRecognition || 
    ((window as unknown) as {
      SpeechRecognition?: new() => WebSpeechRecognition;
      webkitSpeechRecognition?: new() => WebSpeechRecognition;
    }).webkitSpeechRecognition;
    
    if (!SR) throw new Error("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒ Web Speech è¯†åˆ«");
    return new Promise((resolve, reject) => {
      const rec = new SR();
      rec.lang = lang === "zh" ? "zh-CN" : (lang === "ja" ? "ja-JP" : "en-US");
      // å…è®¸ä¸­é—´ç»“æœï¼Œå»¶é•¿è¯´è¯æ—¶é—´çª—å£
      rec.interimResults = true; 
      rec.continuous = true;
      rec.maxAlternatives = 1;
      let txt = "";
      rec.onresult = (e: WebSpeechRecognitionEvent) => { 
        // ç´¯ç§¯æœ€ç»ˆç»“æœï¼Œä¿ç•™æ›´é•¿è¯´è¯æ—¶é•¿
        for (let i = 0; i < e.results.length; i++) {
          const res = e.results[i];
          if (res.isFinal) txt += res[0].transcript;
        }
      };
      rec.onerror = (e: WebSpeechRecognitionErrorEvent) => reject(new Error(e.error || "speech error"));
      rec.onend = () => resolve(txt);
      try { rec.start(); } catch (e) { reject(e); }
    });
  }

  // å°è£…ï¼šæ ¹æ®æµè§ˆå™¨é€‰æ‹©å¯ç”¨çš„åŸç”Ÿè¯†åˆ«ï¼ˆChrome/Safariï¼‰
  function transcribeWithBrowserRecognition(lang: string, onReady: (ctrl: { stop: () => void }) => void): Promise<string> {
    // ä¼˜å…ˆ Chrome Web Speechï¼Œå…¶æ¬¡ Safari webkitSpeechRecognition
    const w = window as unknown as { SpeechRecognition?: unknown; webkitSpeechRecognition?: unknown };
    const hasChrome = !!w.SpeechRecognition || !!w.webkitSpeechRecognition;
    const hasSafari = !!w.webkitSpeechRecognition;
    if (!hasChrome && !hasSafari) {
      return Promise.reject(new Error("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒåŸç”Ÿè¯­éŸ³è¯†åˆ«"));
    }
    // æˆ‘ä»¬ç»Ÿä¸€ç”¨å‰é¢å·²æœ‰çš„ä¸¤ä¸ªå‡½æ•°ä¹‹ä¸€
    const promise = hasSafari
      ? (async () => await transcribeWithWebKitSpeech(lang))()
      : (async () => await transcribeWithWebSpeech(lang))();
    // æš´éœ²ä¸€ä¸ªåœæ­¢æ–¹æ³•ä¾›ä¸Šå±‚åœ¨ç‚¹å‡»åœæ­¢æ—¶è°ƒç”¨
    onReady({
      stop: () => {
        try {
          // Web Speech/ WebKit API éƒ½æ˜¯é€šè¿‡ stop() ç»“æŸï¼Œä½†æˆ‘ä»¬åœ¨å®ç°é‡Œç­‰å¾… onend ä»¥è§£æ
          // è¿™é‡Œæ²¡æœ‰ç›´æ¥çš„å®ä¾‹å¥æŸ„ï¼Œå› ä¸ºæˆ‘ä»¬å°è£…åœ¨å„è‡ªå‡½æ•°å†…éƒ¨ï¼›åœ¨å®è·µä¸­åœæ­¢é€šè¿‡ onend å›è°ƒè§¦å‘
          // ä¸ºç¡®ä¿ä¸€è‡´æ€§ï¼Œåœæ­¢é€»è¾‘äº¤ç»™æµè§ˆå™¨æŒ‰é’®è§¦å‘çš„ rec.stop()ï¼›æœ¬æ–¹æ³•ä¿ç•™ä½œä¸ºå ä½ã€‚
        } catch {}
      }
    });
    return promise;
  }

  // ä¸“ä¸º Safari å®šåˆ¶ï¼šä»…ä½¿ç”¨ webkitSpeechRecognition
  async function transcribeWithWebKitSpeech(lang: string): Promise<string> {
    interface WKEvent extends Event { results: SpeechRecognitionResultList }
    interface WKErr extends Event { error: string }
    interface WKRec extends EventTarget {
      lang: string;
      interimResults: boolean;
      continuous: boolean;
      maxAlternatives: number;
      start(): void;
      stop(): void;
      onresult: (event: WKEvent) => void;
      onerror: (event: WKErr) => void;
      onend: () => void;
    }
    const Ctor = (window as unknown as { webkitSpeechRecognition?: new () => WKRec }).webkitSpeechRecognition;
    if (!Ctor) throw new Error("å½“å‰ Safari æœªæä¾›è¯­éŸ³è¯†åˆ«æ¥å£ï¼ˆwebkitSpeechRecognitionï¼‰");
    return new Promise((resolve, reject) => {
      const rec = new Ctor();
      rec.lang = lang === "zh" ? "zh-CN" : (lang === "ja" ? "ja-JP" : "en-US");
      rec.interimResults = true;
      rec.continuous = true;
      rec.maxAlternatives = 1;
      let txt = "";
      rec.onresult = (e: WKEvent) => {
        for (let i = 0; i < e.results.length; i++) {
          const res = e.results[i];
          if (res.isFinal) txt += res[0].transcript;
        }
      };
      rec.onerror = (e: WKErr) => reject(new Error(e.error || "speech error"));
      rec.onend = () => resolve(txt);
      try { rec.start(); } catch (e) { reject(e as Error); }
    });
  }

  useEffect(() => {
    // æŸäº›æµè§ˆå™¨éœ€è¦å¼‚æ­¥è·å– voices
    if (typeof window !== "undefined" && window.speechSynthesis) {
      window.speechSynthesis.onvoiceschanged = () => {};
    }
  }, []);

  return (
    <main className="max-w-3xl mx-auto p-6 space-y-5">
      <h1 className="text-2xl font-semibold">Shadowing è·Ÿè¯»ç»ƒä¹ ï¼ˆTTS + å½•éŸ³ï¼‰</h1>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
        <label className="flex items-center gap-2">
          <span className="w-24">è¯­è¨€</span>
          <select value={lang} onChange={e=>{const v=e.target.value as "ja"|"en"|"zh"; setLang(v); setTopic(v==="ja"?"æ—¥ç¨‹ã®èª¿æ•´":v==="zh"?"è‡ªæˆ‘ä»‹ç»":"Travel plan");}} className="border rounded px-2 py-1">
            <option value="ja">æ—¥è¯­</option>
            <option value="en">è‹±è¯­</option>
            <option value="zh">ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰</option>
          </select>
        </label>

        <label className="flex items-center gap-2">
          <span className="w-24">æ¨¡å‹</span>
          <select value={model} onChange={e=>setModel(e.target.value)} className="border rounded px-2 py-1">
            {MODELS.map(m=><option key={m.id} value={m.id}>{m.label}</option>)}
          </select>
        </label>

        <label className="flex items-center gap-2 md:col-span-2">
          <span className="w-24">è¯é¢˜</span>
          <input value={topic} onChange={e=>setTopic(e.target.value)} className="border rounded px-2 py-1 flex-1" />
        </label>
      </div>

      <div className="flex gap-2">
        <button onClick={gen} disabled={loading} className="px-3 py-1 rounded bg-black text-white disabled:opacity-60">
          {loading ? "ç”Ÿæˆä¸­..." : "ç”Ÿæˆæ–‡æœ¬"}
        </button>
      </div>

      {err && <div className="text-red-600 text-sm">{err}</div>}

      {data && (
        <>
          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <div className="text-sm text-gray-600">è¯é¢˜ï¼š{data.topic} Â· è¯­è¨€ï¼š{data.lang}</div>
            <p className="whitespace-pre-wrap">{data.text}</p>
          </section>

          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <h3 className="font-medium">Google TTSï¼ˆWaveNet / Neural2ï¼‰</h3>

            <div className="flex flex-wrap items-center gap-2">
              <button onClick={()=>fetchVoices("Neural2")} className="px-3 py-1 rounded border">åˆ·æ–° Neural2</button>
              <button onClick={()=>fetchVoices("WaveNet")} className="px-3 py-1 rounded border">åˆ·æ–° WaveNet</button>
              <button onClick={()=>fetchVoices("all")} className="px-3 py-1 rounded border">å…¨éƒ¨/Standard</button>
              <button onClick={()=>fetchVoices("all")} className="px-3 py-1 rounded border">å…¨éƒ¨å£°éŸ³</button>

              <select value={voiceName} onChange={e=>setVoiceName(e.target.value)} className="border rounded px-2 py-1 min-w-[280px]">
                {voices.map(v => (
                  <option key={v.name} value={v.name}>
                    {v.name} Â· {v.type} Â· {v.ssmlGender?.toString().replace("SSML_VOICE_GENDER_","")}
                  </option>
                ))}
              </select>

              <label className="flex items-center gap-1 text-sm">
                è¯­é€Ÿ
                <input type="number" step="0.1" min="0.25" max="4" value={rate} onChange={e=>setRate(Number(e.target.value)||1)} className="w-20 border rounded px-2 py-1" />
              </label>
              <label className="flex items-center gap-1 text-sm">
                éŸ³é«˜
                <input type="number" step="1" min="-20" max="20" value={pitch} onChange={e=>setPitch(Number(e.target.value)||0)} className="w-20 border rounded px-2 py-1" />
              </label>

              <button onClick={synthGoogle} className="px-3 py-1 rounded bg-black text-white">â–¶ Google TTS åˆæˆ</button>
              <button onClick={saveTts} disabled={!ttsBlob} className="px-3 py-1 rounded bg-emerald-600 text-white disabled:opacity-60">â†‘ ä¿å­˜åˆ°åº“</button>
              <button onClick={speak} className="px-3 py-1 rounded border">å›é€€ï¼šWeb Speech</button>
            </div>

            {ttsUrl && <audio className="mt-2 w-full" controls src={ttsUrl}></audio>}
          </section>

          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <h3 className="font-medium">å½•éŸ³</h3>
            <div className="flex gap-2">
              {recState !== "recording" && <button onClick={startRec} className="px-3 py-1 rounded bg-emerald-600 text-white">â— å¼€å§‹å½•éŸ³</button>}
              {recState === "recording" && <button onClick={stopRec} className="px-3 py-1 rounded bg-red-600 text-white">â–  åœæ­¢</button>}
              <button onClick={upload} disabled={!localUrl} className="px-3 py-1 rounded bg-black text-white disabled:opacity-60">â†‘ ä¸Šä¼ ä¿å­˜</button>
              {localUrl && <a className="px-3 py-1 rounded border" href={localUrl} download>ä¸‹è½½æœ¬åœ°å½•éŸ³</a>}
            </div>

            {localUrl && <audio className="mt-2 w-full" controls src={localUrl}></audio>}
          </section>

          <section className="p-4 bgç™½ rounded-2xl shadow space-y-3">
            <h3 className="font-medium">ğŸ—£ï¸ å£è¯­æµ‹è¯„ï¼ˆå½•éŸ³+è¯†åˆ«ä¸€ä½“ï¼‰</h3>
            <div className="flex flex-wrap items-center gap-2">
              {recState !== "recording" && (
                <button onClick={startLiveAssess} className="px-3 py-1 rounded bg-emerald-600 text-white disabled:opacity-60">â–¶ å¼€å§‹å½•éŸ³å¹¶æµ‹è¯„</button>
              )}
              {recState === "recording" && (
                <button onClick={stopLiveAssess} className="px-3 py-1 rounded bg-red-600 text-white">â–  åœæ­¢å½•éŸ³å¹¶ç”Ÿæˆåé¦ˆ</button>
              )}
              {asrLoading && <span className="text-sm text-gray-500">è¯„æµ‹ä¸­...</span>}
            </div>

            {asrScore && (
              <div className="grid grid-cols-1 md:grid-cols-3 gap-3 text-sm mt-3">
                <div className="p-3 rounded border">
                  <div className="text-gray-500">å‡†ç¡®åº¦</div>
                  <div className="text-2xl">{asrScore.accuracy}%</div>
                </div>
                <div className="p-3 rounded border">
                  <div className="text-gray-500">è¦†ç›–åº¦</div>
                  <div className="text-2xl">{asrScore.coverage}%</div>
                </div>
                <div className="p-3 rounded border">
                  <div className="text-gray-500">è¯­é€Ÿ</div>
                  <div className="text-2xl">{asrScore.speed_wpm || '-'} {lang === 'en' ? 'wpm' : 'å­—/åˆ†'}</div>
                </div>
              </div>
            )}

            {adviceLoading && <div className="text-sm text-gray-500">æ­£åœ¨ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®...</div>}
            {adviceErr && <div className="text-sm text-red-600">{adviceErr}</div>}
            {adviceText && (
              <div className="mt-3 space-y-2">
                <div className="text-sm text-gray-500">AI é’ˆå¯¹æ€§å»ºè®®</div>
                <div className="p-3 rounded bg-amber-50 text-sm whitespace-pre-wrap">{adviceText}</div>
              </div>
            )}

            {asrText && (
              <div className="mt-3 space-y-2">
                <div className="text-sm text-gray-500">è¯†åˆ«æ–‡æœ¬</div>
                <div className="p-3 rounded bg-gray-50 text-sm whitespace-pre-wrap">{asrText}</div>
              </div>
            )}

            {asrDetail.ref.length > 0 && (
              <div className="mt-3 space-y-2">
                <div className="text-sm text-gray-500">é€å¥å¯¹æ¯”</div>
                <div className="space-y-2">
                  {asrDetail.ref.map((sentence, i) => {
                    const hypSent = asrDetail.hyp[i] || "";
                    const { aFlags, bFlags } = lcsFlags(sentence, hypSent);
                    return (
                      <div key={i} className="p-2 rounded border">
                        <div className="text-gray-500">å‚è€ƒ</div>
                        <div>{renderDiffLine(sentence, aFlags)}</div>
                        <div className="text-gray-500 mt-1">è¯†åˆ«</div>
                        <div>{hypSent ? renderDiffLine(hypSent, bFlags) : <span className="text-red-600">(æœªè¯†åˆ«)</span>}</div>
                      </div>
                    );
                  })}
                </div>
              </div>
            )}
          </section>
        </>
      )}
    </main>
  );
}
