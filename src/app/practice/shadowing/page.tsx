"use client";
import React, { useEffect, useRef, useState, useCallback } from "react";

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

interface SpeechRecognition extends EventTarget {
  lang: string;
  interimResults: boolean;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: (event: SpeechRecognitionEvent) => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  onend: () => void;
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}
import { supabase } from "@/lib/supabase";
import { transcribeBlob, type TranscribeOutput, getWhisper, type DownloadProgress } from "@/lib/asr/whisper";
import { transcribeBlobWithVosk, warmUpVosk, type VoskProgress } from "@/lib/asr/vosk";
import { scorePronunciation, splitSentences } from "@/lib/asr/align";

type ShadowingData = { text: string; lang: "ja"|"en"|"zh"; topic: string; approx_duration_sec?: number };

const MODELS = [
  { id: "deepseek-chat", label: "deepseek-chatï¼ˆæ¨èï¼‰" },
  { id: "deepseek-reasoner", label: "deepseek-reasoner" },
];

export default function ShadowingPage() {
  const [lang, setLang] = useState<"ja"|"en"|"zh">("ja");
  const [topic, setTopic] = useState(lang === "ja" ? "æ—¥ç¨‹ã®èª¿æ•´" : lang === "zh" ? "è‡ªæˆ‘ä»‹ç»" : "Travel plan");
  const [model, setModel] = useState("deepseek-chat");
  const [loading, setLoading] = useState(false);
  const [data, setData] = useState<ShadowingData|null>(null);
  const [err, setErr] = useState("");

  // TTS
  const [voices, setVoices] = useState<{name:string; type:string; ssmlGender:string; naturalSampleRateHertz:number}[]>([]);
  const [voiceName, setVoiceName] = useState<string>("");
  const [rate, setRate] = useState<number>(1.0);
  const [pitch, setPitch] = useState<number>(0);
  const [ttsBlob, setTtsBlob] = useState<Blob|null>(null);
  const [ttsUrl, setTtsUrl] = useState<string>("");

  // MediaRecorder
  const [recState, setRecState] = useState<"idle"|"recording"|"stopped">("idle");
  const mediaStreamRef = useRef<MediaStream|null>(null);
  const recorderRef = useRef<MediaRecorder|null>(null);
  const chunksRef = useRef<BlobPart[]>([]);
  const [localUrl, setLocalUrl] = useState<string>("");
  const [recordedBlob, setRecordedBlob] = useState<Blob|null>(null);

  // ASR State
  const [asrBackend, setAsrBackend] = useState<"local-whisper"|"web-speech"|"safari-speech"|"wasm-vosk"|"deepgram">("web-speech");
  const WHISPER_MODELS = [
    { id: "Xenova/whisper-tiny", label: "whisper-tinyï¼ˆæœ€å¿«ï¼‰" },
    { id: "Xenova/whisper-base", label: "whisper-base" },
    { id: "Xenova/whisper-small", label: "whisper-smallï¼ˆæ›´å‡†ï¼‰" },
  ];
  const [whisperModel, setWhisperModel] = useState<string>(WHISPER_MODELS[0].id);
  const [asrText, setAsrText] = useState("");
  const [asrLoading, setAsrLoading] = useState(false);
  const [asrScore, setAsrScore] = useState<{accuracy:number; coverage:number; speed_wpm?:number} | null>(null);
  const [asrDetail, setAsrDetail] = useState<{ref:string[]; hyp:string[]}>({ref:[], hyp:[]});

  // Whisper é¢„ä¸‹è½½/è¿›åº¦
  const [whisperReady, setWhisperReady] = useState(false);
  const [whisperLoading, setWhisperLoading] = useState(false);
  const [whisperProgress, setWhisperProgress] = useState<{ pct: number; status: string; file?: string } | null>(null);
  // Vosk
  const [voskModelUrl, setVoskModelUrl] = useState<string>("");
  const [voskReady, setVoskReady] = useState(false);
  const [voskLoading, setVoskLoading] = useState(false);
  const [voskProgress, setVoskProgress] = useState<{ pct: number; status: string; file?: string } | null>(null);

  // å½“è¯­è¨€å˜åŒ–æˆ–ç‚¹å‡»â€œåˆ·æ–°å£°éŸ³â€æ—¶è·å–å£°éŸ³åˆ—è¡¨
  const fetchVoices = useCallback(async (kind: "Neural2" | "WaveNet" | "Standard" | "all" = "Neural2") => {
    try {
      const r = await fetch(`/api/tts/voices?lang=${lang}&kind=${kind}`);
      const j = await r.json();
      if (Array.isArray(j)) {
        setVoices(j);
        // è‡ªåŠ¨é€‰ç¬¬ä¸€ä¸ª
        if (j.length && !voiceName) setVoiceName(j[0].name);
      } else {
        setErr(j?.error || "æ— æ³•è·å–å£°éŸ³åˆ—è¡¨");
      }
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "æ— æ³•è·å–å£°éŸ³åˆ—è¡¨");
    }
  }, [lang, voiceName]);

  // é¡µé¢æŒ‚è½½æˆ– lang æ”¹å˜æ—¶åˆ·æ–°
  useEffect(() => {
    setVoiceName("");
    // ä¸­æ–‡é»˜è®¤å–å…¨éƒ¨ï¼Œé¿å…æ²¡æœ‰ä¸­æ–‡é€‰é¡¹
    fetchVoices(lang === "zh" ? "all" : "Neural2");
  }, [lang, fetchVoices]);

  // Google æœåŠ¡ç«¯åˆæˆï¼ˆå¤±è´¥å›é€€ Web Speechï¼‰
  const synthGoogle = async () => {
    if (!data?.text) return;
    setErr("");
    try {
      const res = await fetch("/api/tts", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          text: data.text,
          lang,
          voiceName: voiceName || undefined,
          speakingRate: rate,
          pitch
        })
      });
      if (!res.ok) {
        // å›é€€
        speak();
        const t = await res.text();
        setErr(`Google TTS å¤±è´¥ï¼Œå·²å›é€€æœ¬åœ°åˆæˆï¼š${t.slice(0,200)}`);
        return;
      }
      const ab = await res.arrayBuffer();
      const blob = new Blob([ab], { type: "audio/mpeg" });
      setTtsBlob(blob);
      const url = URL.createObjectURL(blob);
      setTtsUrl(url);
    } catch (e: unknown) {
      speak();
      setErr(e instanceof Error ? e.message : "TTS ç½‘ç»œé”™è¯¯ï¼Œå·²å›é€€ Web Speech");
    }
  };

  // Web Speech æœ¬åœ°åˆæˆ
  const speak = () => {
    if (!data?.text) return;
    const synth = window.speechSynthesis;
    if (!synth) { alert("æ­¤æµè§ˆå™¨ä¸æ”¯æŒ Web Speech TTS"); return; }
    const u = new SpeechSynthesisUtterance(data.text);
    // å°è¯•é€‰æ‹©å¯¹åº”è¯­è¨€çš„ voice
    const voices = synth.getVoices();
    const targetLang = lang === "ja" ? "ja" : lang === "zh" ? "zh" : "en";
    const v = voices.find(v => v.lang?.toLowerCase().startsWith(targetLang));
    if (v) u.voice = v;
    u.rate = 1.0;
    u.pitch = 1.0;
    synth.cancel();
    synth.speak(u);
  };

  // ä¿å­˜åˆ° tts æ¡¶
  const saveTts = async () => {
    try {
      if (!ttsBlob) { setErr("æ²¡æœ‰å¯ä¿å­˜çš„ TTS éŸ³é¢‘"); return; }
      const { data: u } = await supabase.auth.getUser();
      const uid = u?.user?.id;
      if (!uid) { setErr("æœªç™»å½•"); return; }
      const ts = Date.now();
      const path = `${uid}/tts-${ts}.mp3`;
      const { error: upErr } = await supabase.storage.from("tts").upload(path, ttsBlob, {
        cacheControl: "3600", upsert: false, contentType: "audio/mpeg",
      });
      if (upErr) { setErr(upErr.message); return; }
      const { data: signed, error: sErr } = await supabase.storage.from("tts").createSignedUrl(path, 60*60*24*7);
      if (sErr) { setErr(sErr.message); return; }
      setTtsUrl(signed!.signedUrl);
      alert("TTS å·²ä¿å­˜åˆ°æˆ‘çš„åº“ï¼ˆé“¾æ¥ 7 å¤©æœ‰æ•ˆï¼‰");
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "ä¿å­˜å¤±è´¥");
    }
  };

  // å½•éŸ³åŠŸèƒ½ä¿æŒä¸å˜
  const startRec = async () => {
    setErr("");
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      const rec = new MediaRecorder(stream, { mimeType: "audio/webm" });
      recorderRef.current = rec;
      chunksRef.current = [];
      // å¼€å§‹æ–°å½•éŸ³å‰æ¸…ç†æ—§çš„æœ¬åœ°éŸ³é¢‘ä¸è¯„æµ‹è¾“å…¥
      setLocalUrl("");
      setRecordedBlob(null);
      rec.ondataavailable = (e: BlobEvent) => { if (e.data?.size) chunksRef.current.push(e.data); };
      rec.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        const url = URL.createObjectURL(blob);
        setLocalUrl(url);
        // å…³é”®ï¼šä¿å­˜å½•éŸ³ Blob ä¾›è¯„æµ‹ä½¿ç”¨
        setRecordedBlob(blob);
      };
      rec.start();
      setRecState("recording");
    } catch (e) {
      setErr(e instanceof Error ? e.message : "æ— æ³•è®¿é—®éº¦å…‹é£");
    }
  };

  const stopRec = () => {
    recorderRef.current?.stop();
    mediaStreamRef.current?.getTracks().forEach(t => t.stop());
    setRecState("stopped");
  };

  const upload = async () => {
    try {
      const { data: u } = await supabase.auth.getUser();
      const uid = u?.user?.id;
      if (!uid) { setErr("æœªç™»å½•"); return; }
      if (chunksRef.current.length === 0) { setErr("æ²¡æœ‰å½•éŸ³æ•°æ®"); return; }

      const blob = new Blob(chunksRef.current, { type: "audio/webm" });
      const ts = Date.now();
      const path = `${uid}/${ts}.webm`;

      const { error: upErr } = await supabase.storage.from("recordings").upload(path, blob, {
        cacheControl: "3600",
        upsert: false,
        contentType: "audio/webm",
      });
      if (upErr) { setErr(upErr.message); return; }

      // ç”Ÿæˆä¸€ä¸ªçŸ­æœŸç­¾å URLï¼ˆ7 å¤©ï¼‰
      const { data: signed, error: sErr } = await supabase.storage
        .from("recordings")
        .createSignedUrl(path, 60 * 60 * 24 * 7);
      if (sErr) { setErr(sErr.message); return; }

      // å†™å…¥ sessions
      if (data) {
        await supabase.from("sessions").insert({
          user_id: uid,
          task_type: "shadowing",
          lang: data.lang,
          topic: data.topic,
          input: { text: data.text },
          output: { audio_path: path, audio_url: signed?.signedUrl },
          ai_feedback: null,
          score: null
        });
      }

      alert("ä¸Šä¼ æˆåŠŸ");
    } catch (e) {
      setErr(e instanceof Error ? e.message : "ä¸Šä¼ å¤±è´¥");
    }
  };

  const gen = async () => {
    setErr(""); setLoading(true); setData(null); setLocalUrl(""); setRecState("idle");
    try {
      const r = await fetch("/api/generate/shadowing", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ lang, topic, model })
      });
      const j = await r.json();
      if (!r.ok) setErr(j?.error || "ç”Ÿæˆå¤±è´¥"); else setData(j);
    } catch (e) {
      setErr(e instanceof Error ? e.message : "ç½‘ç»œé”™è¯¯");
    } finally {
      setLoading(false);
    }
  };

  const warmUpWhisper = async () => {
    try {
      setErr("");
      setWhisperLoading(true);
      setWhisperProgress({ pct: 0, status: "å‡†å¤‡ä¸­..." });
      await getWhisper(whisperModel, (info: DownloadProgress) => {
        const total = typeof info.total === "number" && info.total > 0 ? info.total : undefined;
        const loaded = typeof info.loaded === "number" ? info.loaded : undefined;
        const pct = total && loaded ? Math.min(99, Math.round((loaded / total) * 100)) : 0;
        setWhisperProgress({ pct, status: info.status || "ä¸‹è½½ä¸­...", file: info.file });
      });
      setWhisperReady(true);
      setWhisperProgress(p => p ? { ...p, pct: 100, status: "æ¨¡å‹å·²å°±ç»ª" } : { pct: 100, status: "æ¨¡å‹å·²å°±ç»ª" });
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "æ¨¡å‹ä¸‹è½½å¤±è´¥");
    } finally {
      setWhisperLoading(false);
    }
  };

  const warmUpVoskModel = async () => {
    try {
      setErr("");
      setVoskLoading(true);
      setVoskProgress({ pct: 0, status: "å‡†å¤‡ä¸­..." });
      await warmUpVosk(voskModelUrl, (info: VoskProgress) => {
        const total = typeof info.total === "number" && info.total > 0 ? info.total : undefined;
        const loaded = typeof info.loaded === "number" ? info.loaded : undefined;
        const pct = total && loaded ? Math.min(99, Math.round((loaded / total) * 100)) : 0;
        setVoskProgress({ pct, status: info.status || "ä¸‹è½½ä¸­...", file: info.file });
      });
      setVoskReady(true);
      setVoskProgress(p => p ? { ...p, pct: 100, status: "Vosk æ¨¡å‹å·²å°±ç»ª" } : { pct: 100, status: "Vosk æ¨¡å‹å·²å°±ç»ª" });
    } catch (e: unknown) {
      setErr(e instanceof Error ? e.message : "Vosk æ¨¡å‹ä¸‹è½½å¤±è´¥");
    } finally {
      setVoskLoading(false);
    }
  };

  const fillDefaultVoskUrl = () => {
    const defaults: Record<"ja"|"en"|"zh", string> = {
      zh: "https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip",
      en: "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
      ja: "https://alphacephei.com/vosk/models/vosk-model-small-ja-0.22.zip",
    };
    setVoskModelUrl(defaults[lang]);
  };

  // è¯„æµ‹å…¥å£ï¼šä¼˜å…ˆæœ¬åœ° Whisper
  const evaluate = async () => {
    setErr(""); setAsrLoading(true); setAsrText(""); setAsrScore(null);

    try {
      let hyp = "";
      // ä¼˜å…ˆä½¿ç”¨å½•éŸ³ï¼Œå…¶æ¬¡ TTSï¼›è‹¥ä»…æœ‰æœ¬åœ° URLï¼Œåˆ™å›é€€ä» URL è¯»å– Blob
      let blob: Blob | null = recordedBlob || ttsBlob;
      if (!blob && localUrl) {
        try {
          const r = await fetch(localUrl);
          blob = await r.blob();
        } catch {}
      }
      if (!blob || !blob.size) {
        setErr("æ²¡æœ‰å¯ç”¨çš„éŸ³é¢‘ï¼Œè¯·å…ˆå½•éŸ³æˆ–åˆæˆåå†è¯„æµ‹");
        return;
      }
      const started = Date.now();

      if (asrBackend === "local-whisper") {
        try {
          const out: TranscribeOutput = await transcribeBlob(blob, lang, whisperModel);
          hyp = Array.isArray(out) ? out[0].text : out?.text || "";
          if (!hyp) throw new Error("ASR æ— è¾“å‡ºã€‚å¯èƒ½æ˜¯æ¨¡å‹å°šæœªå®Œå…¨åŠ è½½ï¼Œè¯·é‡è¯•");
        } catch (e: unknown) {
          const msg = e instanceof Error ? e.message : String(e);
          throw new Error(`æœ¬åœ° Whisper è¯†åˆ«å¤±è´¥ï¼š${msg}ã€‚é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç­‰å¾…åŠ è½½å®Œæˆåå†è¯•`);
        }
      } else if (asrBackend === "web-speech") {
        // æµè§ˆå™¨å†…ç½®è¯†åˆ«ï¼ˆChrome å¯ç”¨ï¼›Safari æ”¯æŒæœ‰é™ï¼‰
        // Web Speech åªèƒ½å®æ—¶è¯†åˆ«ï¼Œä¸æ”¯æŒå¯¹å·²å½•éŸ³æ–‡ä»¶è¯†åˆ«
        hyp = await transcribeWithWebSpeech(lang);
      } else if (asrBackend === "safari-speech") {
        // ä»…åœ¨ Safari ä¸‹å¯ç”¨çš„ webkitSpeechRecognition
        hyp = await transcribeWithWebKitSpeech(lang);
      } else if (asrBackend === "wasm-vosk") {
        hyp = await transcribeBlobWithVosk(blob, voskModelUrl);
      } else {
        // å¯é€‰ï¼šäº‘å…œåº•ï¼ˆéœ€é…ç½® Deepgramï¼‰
        const txt = await fetch("/api/asr/deepgram", { method: "POST", body: blob });
        hyp = await txt.text();
      }

      setAsrText(hyp);

      // è¯„åˆ†ä¸é€å¥å¯¹é½
      const refText = data?.text || "";
      const dur = Math.round((Date.now()-started)/1000);
      const sc = scorePronunciation(refText, hyp, lang, dur);
      setAsrScore(sc);
      setAsrDetail({ 
        ref: splitSentences(refText, lang), 
        hyp: splitSentences(hyp, lang) 
      });

      // å†™å…¥ sessions
      const { data: u } = await supabase.auth.getUser();
      if (u?.user?.id) {
        await supabase.from("sessions").insert({
          user_id: u.user.id,
          task_type: "shadowing",
          lang,
          topic: data?.topic,
          input: { text: refText },
          output: { asr_text: hyp, tts_url: ttsUrl || null },
          ai_feedback: { method: asrBackend, ...sc },
          score: sc.accuracy
        });
      }
    } catch (e) {
      setErr(e instanceof Error ? e.message : "è¯„æµ‹å¤±è´¥");
    } finally {
      setAsrLoading(false);
    }
  };

  // Web Speech å›é€€ï¼ˆæç®€ç¤ºä¾‹ï¼‰
  async function transcribeWithWebSpeech(lang: string): Promise<string> {
    interface WebSpeechRecognitionEvent extends Event {
      results: SpeechRecognitionResultList;
    }

    interface WebSpeechRecognitionErrorEvent extends Event {
      error: string;
    }

    interface WebSpeechRecognition extends EventTarget {
      lang: string;
      interimResults: boolean;
      maxAlternatives: number;
      continuous: boolean;
      start(): void;
      onresult: (event: WebSpeechRecognitionEvent) => void;
      onerror: (event: WebSpeechRecognitionErrorEvent) => void;
      onend: () => void;
    }

    const SR = ((window as unknown) as {
      SpeechRecognition?: new() => WebSpeechRecognition;
      webkitSpeechRecognition?: new() => WebSpeechRecognition;
    }).SpeechRecognition || 
    ((window as unknown) as {
      SpeechRecognition?: new() => WebSpeechRecognition;
      webkitSpeechRecognition?: new() => WebSpeechRecognition;
    }).webkitSpeechRecognition;
    
    if (!SR) throw new Error("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒ Web Speech è¯†åˆ«");
    return new Promise((resolve, reject) => {
      const rec = new SR();
      rec.lang = lang === "zh" ? "zh-CN" : (lang === "ja" ? "ja-JP" : "en-US");
      // å…è®¸ä¸­é—´ç»“æœï¼Œå»¶é•¿è¯´è¯æ—¶é—´çª—å£
      rec.interimResults = true; 
      rec.continuous = true;
      rec.maxAlternatives = 1;
      let txt = "";
      rec.onresult = (e: WebSpeechRecognitionEvent) => { 
        // ç´¯ç§¯æœ€ç»ˆç»“æœï¼Œä¿ç•™æ›´é•¿è¯´è¯æ—¶é•¿
        for (let i = 0; i < e.results.length; i++) {
          const res = e.results[i];
          if (res.isFinal) txt += res[0].transcript;
        }
      };
      rec.onerror = (e: WebSpeechRecognitionErrorEvent) => reject(new Error(e.error || "speech error"));
      rec.onend = () => resolve(txt);
      try { rec.start(); } catch (e) { reject(e); }
    });
  }

  // ä¸“ä¸º Safari å®šåˆ¶ï¼šä»…ä½¿ç”¨ webkitSpeechRecognition
  async function transcribeWithWebKitSpeech(lang: string): Promise<string> {
    interface WKEvent extends Event { results: SpeechRecognitionResultList }
    interface WKErr extends Event { error: string }
    interface WKRec extends EventTarget {
      lang: string;
      interimResults: boolean;
      continuous: boolean;
      maxAlternatives: number;
      start(): void;
      stop(): void;
      onresult: (event: WKEvent) => void;
      onerror: (event: WKErr) => void;
      onend: () => void;
    }
    const Ctor = (window as unknown as { webkitSpeechRecognition?: new () => WKRec }).webkitSpeechRecognition;
    if (!Ctor) throw new Error("å½“å‰ Safari æœªæä¾›è¯­éŸ³è¯†åˆ«æ¥å£ï¼ˆwebkitSpeechRecognitionï¼‰");
    return new Promise((resolve, reject) => {
      const rec = new Ctor();
      rec.lang = lang === "zh" ? "zh-CN" : (lang === "ja" ? "ja-JP" : "en-US");
      rec.interimResults = true;
      rec.continuous = true;
      rec.maxAlternatives = 1;
      let txt = "";
      rec.onresult = (e: WKEvent) => {
        for (let i = 0; i < e.results.length; i++) {
          const res = e.results[i];
          if (res.isFinal) txt += res[0].transcript;
        }
      };
      rec.onerror = (e: WKErr) => reject(new Error(e.error || "speech error"));
      rec.onend = () => resolve(txt);
      try { rec.start(); } catch (e) { reject(e as Error); }
    });
  }

  useEffect(() => {
    // æŸäº›æµè§ˆå™¨éœ€è¦å¼‚æ­¥è·å– voices
    if (typeof window !== "undefined" && window.speechSynthesis) {
      window.speechSynthesis.onvoiceschanged = () => {};
    }
  }, []);

  return (
    <main className="max-w-3xl mx-auto p-6 space-y-5">
      <h1 className="text-2xl font-semibold">Shadowing è·Ÿè¯»ç»ƒä¹ ï¼ˆTTS + å½•éŸ³ï¼‰</h1>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
        <label className="flex items-center gap-2">
          <span className="w-24">è¯­è¨€</span>
          <select value={lang} onChange={e=>{const v=e.target.value as "ja"|"en"|"zh"; setLang(v); setTopic(v==="ja"?"æ—¥ç¨‹ã®èª¿æ•´":v==="zh"?"è‡ªæˆ‘ä»‹ç»":"Travel plan");}} className="border rounded px-2 py-1">
            <option value="ja">æ—¥è¯­</option>
            <option value="en">è‹±è¯­</option>
            <option value="zh">ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰</option>
          </select>
        </label>

        <label className="flex items-center gap-2">
          <span className="w-24">æ¨¡å‹</span>
          <select value={model} onChange={e=>setModel(e.target.value)} className="border rounded px-2 py-1">
            {MODELS.map(m=><option key={m.id} value={m.id}>{m.label}</option>)}
          </select>
        </label>

        <label className="flex items-center gap-2 md:col-span-2">
          <span className="w-24">è¯é¢˜</span>
          <input value={topic} onChange={e=>setTopic(e.target.value)} className="border rounded px-2 py-1 flex-1" />
        </label>
      </div>

      <div className="flex gap-2">
        <button onClick={gen} disabled={loading} className="px-3 py-1 rounded bg-black text-white disabled:opacity-60">
          {loading ? "ç”Ÿæˆä¸­..." : "ç”Ÿæˆæ–‡æœ¬"}
        </button>
        <button onClick={warmUpWhisper} disabled={whisperLoading} className="px-3 py-1 rounded border disabled:opacity-60">
          {whisperLoading ? "ä¸‹è½½æ¨¡å‹ä¸­..." : (whisperReady ? "æ¨¡å‹å·²å°±ç»ª" : "ä¸‹è½½/é¢„çƒ­ Whisper æ¨¡å‹")}
        </button>
        {whisperProgress && (
          <span className="text-sm text-gray-600">
            {whisperProgress.status} {whisperProgress.pct}% {whisperProgress.file ? `Â· ${whisperProgress.file}` : ""}
          </span>
        )}
      </div>

      {err && <div className="text-red-600 text-sm">{err}</div>}

      {data && (
        <>
          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <div className="text-sm text-gray-600">è¯é¢˜ï¼š{data.topic} Â· è¯­è¨€ï¼š{data.lang}</div>
            <p className="whitespace-pre-wrap">{data.text}</p>
          </section>

          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <h3 className="font-medium">Google TTSï¼ˆWaveNet / Neural2ï¼‰</h3>

            <div className="flex flex-wrap items-center gap-2">
              <button onClick={()=>fetchVoices("Neural2")} className="px-3 py-1 rounded border">åˆ·æ–° Neural2</button>
              <button onClick={()=>fetchVoices("WaveNet")} className="px-3 py-1 rounded border">åˆ·æ–° WaveNet</button>
              <button onClick={()=>fetchVoices("all")} className="px-3 py-1 rounded border">å…¨éƒ¨/Standard</button>
              <button onClick={()=>fetchVoices("all")} className="px-3 py-1 rounded border">å…¨éƒ¨å£°éŸ³</button>

              <select value={voiceName} onChange={e=>setVoiceName(e.target.value)} className="border rounded px-2 py-1 min-w-[280px]">
                {voices.map(v => (
                  <option key={v.name} value={v.name}>
                    {v.name} Â· {v.type} Â· {v.ssmlGender?.toString().replace("SSML_VOICE_GENDER_","")}
                  </option>
                ))}
              </select>

              <label className="flex items-center gap-1 text-sm">
                è¯­é€Ÿ
                <input type="number" step="0.1" min="0.25" max="4" value={rate} onChange={e=>setRate(Number(e.target.value)||1)} className="w-20 border rounded px-2 py-1" />
              </label>
              <label className="flex items-center gap-1 text-sm">
                éŸ³é«˜
                <input type="number" step="1" min="-20" max="20" value={pitch} onChange={e=>setPitch(Number(e.target.value)||0)} className="w-20 border rounded px-2 py-1" />
              </label>

              <button onClick={synthGoogle} className="px-3 py-1 rounded bg-black text-white">â–¶ Google TTS åˆæˆ</button>
              <button onClick={saveTts} disabled={!ttsBlob} className="px-3 py-1 rounded bg-emerald-600 text-white disabled:opacity-60">â†‘ ä¿å­˜åˆ°åº“</button>
              <button onClick={speak} className="px-3 py-1 rounded border">å›é€€ï¼šWeb Speech</button>
            </div>

            {ttsUrl && <audio className="mt-2 w-full" controls src={ttsUrl}></audio>}
          </section>

          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <h3 className="font-medium">å½•éŸ³</h3>
            <div className="flex gap-2">
              {recState !== "recording" && <button onClick={startRec} className="px-3 py-1 rounded bg-emerald-600 text-white">â— å¼€å§‹å½•éŸ³</button>}
              {recState === "recording" && <button onClick={stopRec} className="px-3 py-1 rounded bg-red-600 text-white">â–  åœæ­¢</button>}
              <button onClick={upload} disabled={!localUrl} className="px-3 py-1 rounded bg-black text-white disabled:opacity-60">â†‘ ä¸Šä¼ ä¿å­˜</button>
              {localUrl && <a className="px-3 py-1 rounded border" href={localUrl} download>ä¸‹è½½æœ¬åœ°å½•éŸ³</a>}
            </div>

            {localUrl && <audio className="mt-2 w-full" controls src={localUrl}></audio>}
          </section>

          <section className="p-4 bg-white rounded-2xl shadow space-y-3">
            <h3 className="font-medium">ğŸ—£ï¸ å£è¯­æµ‹è¯„ï¼ˆASRï¼‰</h3>
            <div className="flex flex-wrap items-center gap-2">
              <label className="flex items-center gap-2">
                <span>ASR å¼•æ“</span>
                <select 
                  value={asrBackend} 
                  onChange={e => setAsrBackend(e.target.value as "local-whisper"|"web-speech"|"safari-speech"|"wasm-vosk"|"deepgram")}
                  className="border rounded px-2 py-1"
                >
                  <option value="web-speech">Web Speechï¼ˆChromeï¼‰</option>
                  <option value="local-whisper">æœ¬åœ° Whisper</option>
                  <option value="safari-speech">Safari è¯­éŸ³è¯†åˆ«ï¼ˆå®éªŒï¼‰</option>
                  <option value="wasm-vosk">æœ¬åœ°è½»é‡å¼•æ“ï¼ˆWASM/Voskï¼‰</option>
                  <option value="deepgram">Deepgramï¼ˆéœ€é…ç½®ï¼‰</option>
                </select>
              </label>
              {asrBackend === 'local-whisper' && (
                <label className="flex items-center gap-2">
                  <span>Whisper æ¨¡å‹</span>
                  <select value={whisperModel} onChange={e=>setWhisperModel(e.target.value)} className="border rounded px-2 py-1">
                    {WHISPER_MODELS.map(m => <option key={m.id} value={m.id}>{m.label}</option>)}
                  </select>
                </label>
              )}
              
              {asrBackend === 'wasm-vosk' && (
                <>
                  <label className="flex items-center gap-2">
                    <span>Vosk æ¨¡å‹ URL</span>
                    <input
                      value={voskModelUrl}
                      onChange={e=>setVoskModelUrl(e.target.value)}
                      placeholder="https://.../vosk-model-small-xx.tar.gz"
                      className="border rounded px-2 py-1 w-[380px]"
                    />
                  </label>
                  <button onClick={fillDefaultVoskUrl} className="px-3 py-1 rounded border">ä¸€é”®å¡«é»˜è®¤æ¨¡å‹ URL</button>
                  <span className="text-xs text-gray-500">ä½ ä¹Ÿå¯ä»¥æŠŠæ¨¡å‹å‹ç¼©åŒ…æ”¾åˆ° public/models ä¸‹ï¼Œå¡«å…¥ä¾‹å¦‚ /models/vosk-model-small-cn-0.22.zip ä»¥èµ°åŒæºåŠ è½½</span>
                  <button onClick={warmUpVoskModel} disabled={voskLoading || !voskModelUrl} className="px-3 py-1 rounded border disabled:opacity-60">
                    {voskLoading ? "ä¸‹è½½ Vosk ä¸­..." : (voskReady ? "Vosk å·²å°±ç»ª" : "ä¸‹è½½/é¢„çƒ­ Vosk æ¨¡å‹")}
                  </button>
                  {voskProgress && (
                    <span className="text-sm text-gray-600">
                      {voskProgress.status} {voskProgress.pct}% {voskProgress.file ? `Â· ${voskProgress.file}` : ""}
                    </span>
                  )}
                </>
              )}
              <button 
                onClick={evaluate} 
                disabled={
                  asrLoading || (
                    asrBackend === 'local-whisper' ? (!recordedBlob && !ttsBlob) || !whisperReady :
                    asrBackend === 'deepgram' ? (!recordedBlob && !ttsBlob) :
                    asrBackend === 'wasm-vosk' ? (!recordedBlob && !ttsBlob) || !voskReady || !voskModelUrl :
                    false
                  )
                }
                className="px-3 py-1 rounded bg-black text-white disabled:opacity-60"
              >
                {asrLoading ? "è¯„æµ‹ä¸­..." : "å¼€å§‹è¯„æµ‹"}
              </button>
              {asrBackend === 'wasm-vosk' && (
                <span className="text-sm text-gray-500">è¯·å…ˆå¡«å†™æ¨¡å‹ URL å¹¶ç‚¹å‡»â€œä¸‹è½½/é¢„çƒ­ Vosk æ¨¡å‹â€</span>
              )}
              {asrBackend === 'local-whisper' && !whisperReady && (
                <span className="text-sm text-gray-500">è¯·å…ˆç‚¹å‡»â€œä¸‹è½½/é¢„çƒ­ Whisper æ¨¡å‹â€å¹¶ç­‰å¾…è‡³ 100%</span>
              )}
            </div>

            {asrScore && (
              <div className="grid grid-cols-1 md:grid-cols-3 gap-3 text-sm mt-3">
                <div className="p-3 rounded border">
                  <div className="text-gray-500">å‡†ç¡®åº¦</div>
                  <div className="text-2xl">{asrScore.accuracy}%</div>
                </div>
                <div className="p-3 rounded border">
                  <div className="text-gray-500">è¦†ç›–åº¦</div>
                  <div className="text-2xl">{asrScore.coverage}%</div>
                </div>
                <div className="p-3 rounded border">
                  <div className="text-gray-500">è¯­é€Ÿ</div>
                  <div className="text-2xl">{asrScore.speed_wpm || '-'} {lang === 'en' ? 'wpm' : 'å­—/åˆ†'}</div>
                </div>
              </div>
            )}

            {asrText && (
              <div className="mt-3 space-y-2">
                <div className="text-sm text-gray-500">è¯†åˆ«æ–‡æœ¬</div>
                <div className="p-3 rounded bg-gray-50 text-sm whitespace-pre-wrap">{asrText}</div>
              </div>
            )}

            {asrDetail.ref.length > 0 && (
              <div className="mt-3 space-y-2">
                <div className="text-sm text-gray-500">é€å¥å¯¹æ¯”</div>
                <div className="space-y-2">
                  {asrDetail.ref.map((sentence, i) => (
                    <div key={i} className="p-2 rounded border">
                      <div className="text-gray-500">å‚è€ƒ</div>
                      <div>{sentence}</div>
                      <div className="text-gray-500 mt-1">è¯†åˆ«</div>
                      <div>{asrDetail.hyp[i] || "(æœªè¯†åˆ«)"}</div>
                    </div>
                  ))}
                </div>
              </div>
            )}
          </section>
        </>
      )}
    </main>
  );
}
