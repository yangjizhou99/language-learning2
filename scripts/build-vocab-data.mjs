/**
 * Script to download and process vocabulary databases
 * Run with: node scripts/build-vocab-data.mjs
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const OUTPUT_DIR = path.join(__dirname, '..', 'src', 'data', 'vocab');

// Ensure output directory exists
if (!fs.existsSync(OUTPUT_DIR)) {
    fs.mkdirSync(OUTPUT_DIR, { recursive: true });
}

/**
 * Fetch and process English CEFR vocabulary
 */
async function processEnglishCEFR() {
    console.log('ðŸ“š Processing English CEFR vocabulary...');

    const url = 'https://raw.githubusercontent.com/openlanguageprofiles/olp-en-cefrj/master/cefrj-vocabulary-profile-1.5.csv';
    const response = await fetch(url);
    const csv = await response.text();

    const dict = {};
    const lines = csv.split('\n');

    // Skip header: headword,pos,CEFR,CoreInventory 1,CoreInventory 2,Threshold
    for (let i = 1; i < lines.length; i++) {
        const line = lines[i].trim();
        if (!line) continue;

        // Parse CSV (handle potential quoted fields)
        const parts = line.split(',');
        const headword = parts[0]?.toLowerCase().trim();
        const level = parts[2]?.trim(); // CEFR column

        if (headword && level && ['A1', 'A2', 'B1', 'B2', 'C1', 'C2'].includes(level)) {
            // Only keep first occurrence (some words have multiple entries)
            if (!dict[headword]) {
                dict[headword] = level;
            }
        }
    }

    const outputPath = path.join(OUTPUT_DIR, 'en-cefr.json');
    fs.writeFileSync(outputPath, JSON.stringify(dict, null, 0));

    console.log(`   âœ… Saved ${Object.keys(dict).length} English words to ${outputPath}`);
    return dict;
}

/**
 * Fetch and process Japanese JLPT vocabulary
 */
async function processJapaneseJLPT() {
    console.log('ðŸ“š Processing Japanese JLPT vocabulary...');

    const dict = {};
    const levels = ['n5', 'n4', 'n3', 'n2', 'n1'];

    for (const level of levels) {
        try {
            // Try the output folder structure
            const url = `https://raw.githubusercontent.com/elzup/jlpt-word-list/master/out/${level}.json`;
            const response = await fetch(url);

            if (!response.ok) {
                console.log(`   âš ï¸ Could not fetch ${level}, trying alternative...`);
                continue;
            }

            const words = await response.json();

            // Handle both array format and object format
            if (Array.isArray(words)) {
                words.forEach(word => {
                    const key = typeof word === 'string' ? word : word.word || word.kanji || word.reading;
                    if (key && !dict[key]) {
                        dict[key] = level.toUpperCase();
                    }
                });
            }
        } catch (err) {
            console.log(`   âš ï¸ Error processing ${level}: ${err.message}`);
        }
    }

    // If we couldn't get data, use a fallback built-in list
    if (Object.keys(dict).length === 0) {
        console.log('   âš ï¸ Using fallback JLPT data...');
        // Common N5 words as fallback
        const fallbackN5 = ['ç§', 'äºº', 'æ—¥', 'æœˆ', 'å¹´', 'ä»Š', 'æ™‚', 'ä½•', 'å‰', 'å¾Œ', 'ä¸­', 'ä¸Š', 'ä¸‹', 'å¤§', 'å°', 'é«˜', 'å®‰', 'æ–°', 'å¤', 'ç™½', 'é»’', 'èµ¤', 'é’', 'å­¦æ ¡', 'ä¼šç¤¾', 'ç—…é™¢', 'é§…', 'é›»è»Š', 'è»Š', 'é“', 'å±±', 'å·', 'æµ·', 'ç©º', 'é›¨', 'é›ª', 'é¢¨', 'èŠ±', 'æœ¨', 'çŠ¬', 'çŒ«', 'é­š', 'é³¥', 'é£Ÿã¹ã‚‹', 'é£²ã‚€', 'è¦‹ã‚‹', 'èžã', 'èª­ã‚€', 'æ›¸ã', 'è©±ã™', 'è¡Œã', 'æ¥ã‚‹', 'å¸°ã‚‹', 'å…¥ã‚‹', 'å‡ºã‚‹', 'ç«‹ã¤', 'åº§ã‚‹', 'èµ°ã‚‹', 'æ­©ã', 'æ³³ã', 'è²·ã†', 'å£²ã‚‹', 'ä½¿ã†', 'ä½œã‚‹', 'é–‹ã‘ã‚‹', 'é–‰ã‚ã‚‹', 'å§‹ã‚ã‚‹', 'çµ‚ã‚ã‚‹', 'ä½ã‚€', 'åƒã', 'ä¼‘ã‚€', 'å¯ã‚‹', 'èµ·ãã‚‹', 'ç€ã‚‹', 'è„±ã', 'æ´—ã†', 'æŒã¤', 'ç½®ã', 'å–ã‚‹', 'åˆ†ã‹ã‚‹', 'æ€ã†', 'çŸ¥ã‚‹', 'å¥½ã', 'å«Œã„', 'å¤§ãã„', 'å°ã•ã„', 'å¤šã„', 'å°‘ãªã„', 'é•·ã„', 'çŸ­ã„', 'é«˜ã„', 'ä½Žã„', 'è‰¯ã„', 'æ‚ªã„', 'æ–°ã—ã„', 'å¤ã„', 'æ—©ã„', 'é…ã„', 'è¿‘ã„', 'é ã„', 'ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ', 'ã“ã“', 'ãã“', 'ã‚ãã“', 'èª°', 'ã©ã“', 'ã„ã¤', 'ãªãœ'];
        fallbackN5.forEach(w => { dict[w] = 'N5'; });

        // Common N4 words
        const fallbackN4 = ['çµŒé¨“', 'é–¢ä¿‚', 'ç¤¾ä¼š', 'æ”¿æ²»', 'çµŒæ¸ˆ', 'æ–‡åŒ–', 'æ­´å²', 'ç§‘å­¦', 'æŠ€è¡“', 'ç’°å¢ƒ', 'å•é¡Œ', 'æ„è¦‹', 'èª¬æ˜Ž', 'ç´¹ä»‹', 'è³ªå•', 'å›žç­”', 'é€£çµ¡', 'ç›¸è«‡', 'ç´„æŸ', 'äºˆå®š', 'è¨ˆç”»', 'æº–å‚™', 'å‚åŠ ', 'å‡ºå¸­', 'æ¬ å¸­', 'é…åˆ»', 'äºˆç´„', 'æ³¨æ–‡', 'å¤‰æ›´', 'å–æ¶ˆ'];
        fallbackN4.forEach(w => { if (!dict[w]) dict[w] = 'N4'; });

        // Common N3 words  
        const fallbackN3 = ['è­°è«–', 'ææ¡ˆ', 'è§£æ±º', 'æ±ºå®š', 'åˆ¤æ–­', 'é¸æŠž', 'æ¯”è¼ƒ', 'è©•ä¾¡', 'åˆ†æž', 'èª¿æŸ»', 'ç ”ç©¶', 'é–‹ç™º', 'è£½é€ ', 'è²©å£²', 'è³¼å…¥', 'å¥‘ç´„', 'äº¤æ¸‰', 'å”åŠ›', 'ç«¶äº‰', 'æˆåŠŸ', 'å¤±æ•—', 'åŠªåŠ›', 'æŒ‘æˆ¦', 'é”æˆ', 'ç¶­æŒ', 'æ”¹å–„', 'å‘ä¸Š', 'ç™ºå±•', 'é€²æ­©', 'å¤‰åŒ–'];
        fallbackN3.forEach(w => { if (!dict[w]) dict[w] = 'N3'; });
    }

    const outputPath = path.join(OUTPUT_DIR, 'ja-jlpt.json');
    fs.writeFileSync(outputPath, JSON.stringify(dict, null, 0));

    console.log(`   âœ… Saved ${Object.keys(dict).length} Japanese words to ${outputPath}`);
    return dict;
}

/**
 * Fetch and process Chinese HSK vocabulary
 */
async function processChineseHSK() {
    console.log('ðŸ“š Processing Chinese HSK vocabulary...');

    const url = 'https://raw.githubusercontent.com/drkameleon/complete-hsk-vocabulary/main/complete.json';
    const response = await fetch(url);
    const data = await response.json();

    const dict = {};

    data.forEach(entry => {
        const word = entry.simplified;
        const levels = entry.level || [];

        // Find the lowest (easiest) HSK level
        let hskLevel = null;
        for (const lvl of levels) {
            // Match patterns like "old-1", "old-2", "new-1", etc.
            const match = lvl.match(/(?:old|new)-(\d+)/);
            if (match) {
                const num = parseInt(match[1]);
                if (!hskLevel || num < hskLevel) {
                    hskLevel = num;
                }
            }
        }

        if (word && hskLevel) {
            if (!dict[word]) {
                dict[word] = `HSK${hskLevel}`;
            }
        }
    });

    const outputPath = path.join(OUTPUT_DIR, 'zh-hsk.json');
    fs.writeFileSync(outputPath, JSON.stringify(dict, null, 0));

    console.log(`   âœ… Saved ${Object.keys(dict).length} Chinese words to ${outputPath}`);
    return dict;
}

// Main execution
async function main() {
    console.log('ðŸš€ Building vocabulary data files...\n');

    try {
        await processEnglishCEFR();
        await processJapaneseJLPT();
        await processChineseHSK();

        console.log('\nâœ… All vocabulary data files created successfully!');
    } catch (err) {
        console.error('âŒ Error:', err);
        process.exit(1);
    }
}

main();
